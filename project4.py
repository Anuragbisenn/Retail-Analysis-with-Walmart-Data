# -*- coding: utf-8 -*-
"""project4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19aSvVqiZPjrgJoq11SRV7f9KaFLEQFoZ

# import requre libraries
"""

import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt
import sklearn 
import seaborn as sns

"""###import  dataset into pandas dataframe """

data=pd.read_csv('/content/drive/MyDrive/simplilearn/python with data science /project4/Walmart_Store_sales.csv')

data.head()

data.describe()

data.shape

"""**which store has maximum sales**"""

sales_for_store=data.groupby('Store')['Weekly_Sales'].sum()

sales_for_store.head(5)

sales_for_store.max()

sales_for_store.idxmax()

sales_for_store[20]

"""**which state has maximum variation in statnderd deviation**"""

max_std=data.groupby('Store')['Weekly_Sales'].std()

max_std

max_std.idxmax()

max_std[14]

"""**Which store/s has good quarterly growth rate in Q3’2012**"""

data.Date=pd.to_datetime( data['Date'],infer_datetime_format='%d-%m-%y')



walmart_dataset_Q32012 = data[((data['Date']) >= pd.to_datetime('01-07-2012',format="%d-%m-%Y")) &
                                         ((data['Date']) <= pd.to_datetime('30-09-2012',format="%d-%m-%Y"))]
walmart_dataset_Q32012

walmart_dataset_Q32012.groupby(['Store'])['Weekly_Sales'].sum().max()

walmart_dataset_Q32012.groupby(['Store'])['Weekly_Sales'].sum().idxmax()

"""so in the index num 4 we have max Q3 that is 25652119.35

**4 Some holidays have a negative impact on sales. Find out holidays which have higher sales than the mean sales in non-holiday season for all stores together**
"""

Christmas_sales=data.loc[(data["Date"]==pd.to_datetime("31-12-2010")) |
                        (data["Date"]==pd.to_datetime("30-12-2011")) | 
                        (data["Date"]==pd.to_datetime("28-12-2012")) | 
                        (data["Date"]==pd.to_datetime("27-12-2013"))]
Christmas_sales

Thanksgiving=data.loc[(data["Date"]==pd.to_datetime("26-11-2010")) |
                                 (data["Date"]==pd.to_datetime("25-11-2011")) |
                                 (data["Date"]==pd.to_datetime("23-11-2012")) |
                                 (data["Date"]==pd.to_datetime("29-11-2013"))]
Thanksgiving

Labour_day=data.loc[(data["Date"]==pd.to_datetime("10-09-2010",format="%d-%m-%Y")) | 
                               (data["Date"]==pd.to_datetime("09-09-2011",format="%d-%m-%Y")) | 
                               (data["Date"]==pd.to_datetime("07-09-2012",format="%d-%m-%Y")) | 
                               (data["Date"]==pd.to_datetime("06-09-2013",format="%d-%m-%Y"))]
Labour_day

Super_Bowl=data.loc[(data["Date"]==pd.to_datetime("12-02-2010",format="%d-%m-%Y")) |
                               (data["Date"]==pd.to_datetime("11-02-2011",format="%d-%m-%Y")) |
                               (data["Date"]==pd.to_datetime("10-02-2012",format="%d-%m-%Y")) |
                               (data["Date"]==pd.to_datetime("08-02-2013",format="%d-%m-%Y"))]
Super_Bowl.shape

holiday_sale=data.loc[data['Holiday_Flag']==1]

holiday_sale

non_holiday=data.loc[data['Holiday_Flag']==0]
non_holiday.head()

"""###Some holidays have a negative impact on sales. Find out holidays which have higher sales than the mean sales in non-holiday season for all stores together


"""

A=non_holiday.Weekly_Sales.mean()

non_holidayweek_sale_mean=non_holiday.groupby("Date").agg({"Weekly_Sales":'mean'}).reset_index()
non_holidayweek_sale_mean

holiday_sale_total=holiday_sale.groupby('Date').agg({"Weekly_Sales":'mean'}).reset_index()

holiday_sale_total

for X in holiday_sale_total.itertuples():
    for X1 in non_holidayweek_sale_mean.itertuples():
        if X.Weekly_Sales > X1.Weekly_Sales:
            print("On Date {} , Holiday sales are greater than Non_Holiday_mean_sales and the sales:- {}"
                  .format(X.Date,X.Weekly_Sales))
            break;



"""###Provide a monthly and semester view of sales in units and give insights"""

data["Year"]= pd.DatetimeIndex(data['Date']).year
data["Month"]= pd.DatetimeIndex(data['Date']).month

data.head()

""" **month wise analisis**"""

data_2010=data.loc[data['Year']==2010]
data_2011=data.loc[data['Year']==2011]
data_2012=data.loc[data['Year']==2012]



plt.style.use("ggplot")
plt.figure(figsize=(10,7) )
plt.scatter(data_2010["Month"],data_2010["Weekly_Sales"] )
plt.xlabel("Month")
plt.ylabel("Weekly_Sales")
plt.title("Monthly view of sales in 2010")

plt.style.use("ggplot")
plt.figure(figsize=(10,7))
plt.scatter(data_2011["Month"],data_2011["Weekly_Sales"])
plt.xlabel("Month")
plt.ylabel("Weekly_Sales")
plt.title("Monthly view of sales in 2010")

plt.style.use("ggplot")
plt.figure(figsize=(10,7))
plt.scatter(data_2012["Month"],data_2012["Weekly_Sales"])
plt.xlabel("Month")
plt.ylabel("Weekly_Sales")
plt.title("Monthly view of sales in 2010")

"""**semester wise analisis**"""

semester_sales=[]
semester_sales.append(data_2010.loc[data_2010["Month"]<7,["Weekly_Sales"]].sum())
semester_sales.append(data_2010.loc[data_2010["Month"]>6,["Weekly_Sales"]].sum())
semester_sales.append(data_2011.loc[data_2011["Month"]<7,["Weekly_Sales"]].sum())
semester_sales.append(data_2011.loc[data_2011["Month"]>6,["Weekly_Sales"]].sum())
semester_sales.append(data_2012.loc[data_2012["Month"]<7,["Weekly_Sales"]].sum())
semester_sales.append(data_2012.loc[data_2012["Month"]>6,["Weekly_Sales"]].sum())

semester_sales

sem_name=["1st_sem_2010",'2nd_sem_2010','1sem_2011','2ndsem_2011','1sem_2012','2ndsem_2012']

plt.figure(figsize=(10,6))
plt.plot(sem_name,semester_sales)
plt.xlabel("Semesters")
plt.ylabel("Semester Sales")
plt.title("Semester view of sales")

#Restructure dates as 1 for 5 Feb 2010 (starting from the earliest date in order)

x_object1=data[data['Store'] == 1][['Store','Date']]
x_object1

"""# Statistical Model

### For Store 1 – Build  prediction models to forecast demand

### Hypothesize if CPI, unemployment, and fuel price have any impact on sales.
"""

X_feature=data.drop(["Weekly_Sales","Holiday_Flag","Date","Year","Month","Unemployment"],axis=1)
X_feature=X_feature[X_feature["Store"]==1]
Y_target=data[data['Store']==1]["Weekly_Sales"]
print (X_feature)
print (Y_target)

# Splitting the data into training & testing datasets(75:25)
import sklearn
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X_feature,Y_target,test_size=0.25,random_state=0 )

print (X_train.shape)
print (Y_train.shape)

print (X_test.shape)
print (Y_test.shape)

#import linear model
from sklearn.linear_model import LinearRegression
#creating instance of the class also called estimator
linreg = LinearRegression(normalize=True,n_jobs=-1)

from sklearn.metrics import mean_squared_error

#fit data into estimator
linreg.fit(X_train,Y_train)

print(format(linreg.score(X_test,Y_test)*100))

linreg.score(X_train,Y_train)*100

print(np.sqrt(mean_squared_error(Y_train,linreg.predict(X_train))))

print(np.sqrt(mean_squared_error(Y_test,linreg.predict(X_test))))

print(linreg.intercept_)
print(linreg.coef_)

import seaborn as sns

data.columns

col=['Weekly_Sales','Fuel_Price', 'CPI', 'Unemployment']

ax=sns.heatmap(data[col].corr())

"""here we can say fuel price has positive impect  on sales and second cpi is also the positive impect on sale but unemployment feture has a negative impect on weekly_sales

##Change dates into days by creating new variable.
"""

data['day']=pd.to_datetime(data['Date']).dt.day_name()

data

**********************************************end****************************by anurag bisen